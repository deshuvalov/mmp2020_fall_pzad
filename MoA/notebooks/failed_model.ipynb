{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-22T16:29:52.373945Z",
     "iopub.status.busy": "2020-10-22T16:29:52.373166Z",
     "iopub.status.idle": "2020-10-22T16:29:54.470326Z",
     "shell.execute_reply": "2020-10-22T16:29:54.469159Z"
    },
    "papermill": {
     "duration": 2.114249,
     "end_time": "2020-10-22T16:29:54.470452",
     "exception": false,
     "start_time": "2020-10-22T16:29:52.356203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#used net arch from kaggle.com/nicohrubec/pytorch-multilabel-neural-network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.special import erf, erfinv\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import FLOAT_DTYPES, check_array, check_is_fitted\n",
    "\n",
    "\n",
    "class GaussRankScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transform features by scaling each feature to a normal distribution.\n",
    "    Parameters\n",
    "        ----------\n",
    "        epsilon : float, optional, default 1e-4\n",
    "            A small amount added to the lower bound or subtracted\n",
    "            from the upper bound. This value prevents infinite number\n",
    "            from occurring when applying the inverse error function.\n",
    "        copy : boolean, optional, default True\n",
    "            If False, try to avoid a copy and do inplace scaling instead.\n",
    "            This is not guaranteed to always work inplace; e.g. if the data is\n",
    "            not a NumPy array, a copy may still be returned.\n",
    "        n_jobs : int or None, optional, default None\n",
    "            Number of jobs to run in parallel.\n",
    "            ``None`` means 1 and ``-1`` means using all processors.\n",
    "        interp_kind : str or int, optional, default 'linear'\n",
    "           Specifies the kind of interpolation as a string\n",
    "            ('linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
    "            'previous', 'next', where 'zero', 'slinear', 'quadratic' and 'cubic'\n",
    "            refer to a spline interpolation of zeroth, first, second or third\n",
    "            order; 'previous' and 'next' simply return the previous or next value\n",
    "            of the point) or as an integer specifying the order of the spline\n",
    "            interpolator to use.\n",
    "        interp_copy : bool, optional, default False\n",
    "            If True, the interpolation function makes internal copies of x and y.\n",
    "            If False, references to `x` and `y` are used.\n",
    "        Attributes\n",
    "        ----------\n",
    "        interp_func_ : list\n",
    "            The interpolation function for each feature in the training set.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=1e-4, copy=True, n_jobs=None, interp_kind='linear', interp_copy=False):\n",
    "        self.epsilon = epsilon\n",
    "        self.copy = copy\n",
    "        self.interp_kind = interp_kind\n",
    "        self.interp_copy = interp_copy\n",
    "        self.fill_value = 'extrapolate'\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit interpolation function to link rank with original data for future scaling\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The data used to fit interpolation function for later scaling along the features axis.\n",
    "        y\n",
    "            Ignored\n",
    "        \"\"\"\n",
    "        X = check_array(X, copy=self.copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        self.interp_func_ = Parallel(n_jobs=self.n_jobs)(delayed(self._fit)(x) for x in X.T)\n",
    "        return self\n",
    "\n",
    "    def _fit(self, x):\n",
    "        x = self.drop_duplicates(x)\n",
    "        rank = np.argsort(np.argsort(x))\n",
    "        bound = 1.0 - self.epsilon\n",
    "        factor = np.max(rank) / 2.0 * bound\n",
    "        scaled_rank = np.clip(rank / factor - bound, -bound, bound)\n",
    "        return interp1d(\n",
    "            x, scaled_rank, kind=self.interp_kind, copy=self.interp_copy, fill_value=self.fill_value)\n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "        \"\"\"Scale the data with the Gauss Rank algorithm\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The data used to scale along the features axis.\n",
    "        copy : bool, optional (default: None)\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        X = check_array(X, copy=copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _transform(self, i, x):\n",
    "        return erfinv(self.interp_func_[i](x))\n",
    "\n",
    "    def inverse_transform(self, X, copy=None):\n",
    "        \"\"\"Scale back the data to the original representation\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data used to scale along the features axis.\n",
    "        copy : bool, optional (default: None)\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        X = check_array(X, copy=copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._inverse_transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _inverse_transform(self, i, x):\n",
    "        inv_interp_func = interp1d(self.interp_func_[i].y, self.interp_func_[i].x, kind=self.interp_kind,\n",
    "                                   copy=self.interp_copy, fill_value=self.fill_value)\n",
    "        return inv_interp_func(erf(x))\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_duplicates(x):\n",
    "        is_unique = np.zeros_like(x, dtype=bool)\n",
    "        is_unique[np.unique(x, return_index=True)[1]] = True\n",
    "        return x[is_unique]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T16:37:34.681948Z",
     "iopub.status.busy": "2020-10-22T16:37:34.681054Z",
     "iopub.status.idle": "2020-10-22T16:37:37.116522Z",
     "shell.execute_reply": "2020-10-22T16:37:37.115565Z"
    },
    "papermill": {
     "duration": 2.569225,
     "end_time": "2020-10-22T16:37:37.116651",
     "exception": false,
     "start_time": "2020-10-22T16:37:34.547426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "submit[targets] = preds\n",
    "submit.loc[X_test['cp_type']=='ctl_vehicle', targets] = 0\n",
    "submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CDLL 'caffe2_nvrtc.dll', handle 7ffae7c50000 at 0x2dada452430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "ctypes.cdll.LoadLibrary('caffe2_nvrtc.dll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_min = 1e-15\n",
    "p_max = 1 - p_min\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    y_pred = np.clip(y_pred, p_min, p_max)\n",
    "    return -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv('../input/lish-moa/train_features.csv', index_col='sig_id')\n",
    "test_Y = pd.read_csv('../input/lish-moa/sample_submission.csv', index_col='sig_id')\n",
    "train_Y = pd.read_csv('../input/lish-moa/train_targets_scored.csv', index_col='sig_id', dtype={f: test_Y.dtypes[f] for f in test_Y})\n",
    "test_X = pd.read_csv('../input/lish-moa/test_features.csv', index_col='sig_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.cp_time = train_X.cp_time / 24\n",
    "test_X.cp_time = test_X.cp_time / 24\n",
    "\n",
    "train_X['real_drug'] = train_X.cp_type == 'trt_cp'\n",
    "test_X['real_drug'] = test_X.cp_type == 'trt_cp'\n",
    "\n",
    "t = train_X.cp_dose.copy()\n",
    "train_X.drop(columns=['cp_dose', 'cp_type'], inplace=True)\n",
    "train_X['cp_dose'] = 1\n",
    "train_X.loc[(t == 'D2'), 'cp_dose'] = 2\n",
    "\n",
    "t = test_X.cp_dose.copy()\n",
    "test_X.drop(columns=['cp_dose', 'cp_type'], inplace=True)\n",
    "test_X['cp_dose'] = 1\n",
    "test_X.loc[(t == 'D2'), 'cp_dose'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 6\n",
    "nstarts = 1\n",
    "nepochs = 50\n",
    "batch_size = 128\n",
    "val_batch_size = batch_size * 4\n",
    "criterion = nn.BCELoss()\n",
    "kfold = MultilabelStratifiedKFold(n_splits=nfolds, random_state=517, shuffle=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T16:30:02.716430Z",
     "iopub.status.busy": "2020-10-22T16:30:02.715242Z",
     "iopub.status.idle": "2020-10-22T16:30:02.717724Z",
     "shell.execute_reply": "2020-10-22T16:30:02.718219Z"
    },
    "papermill": {
     "duration": 0.019882,
     "end_time": "2020-10-22T16:30:02.718337",
     "exception": false,
     "start_time": "2020-10-22T16:30:02.698455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset_my(Dataset):\n",
    "    def __init__(self, df, targets, mode='train'):\n",
    "        self.mode = mode\n",
    "        #self.feats = feats_idx\n",
    "        #self.data = df[:, feats_idx]\n",
    "        self.data = df\n",
    "        if mode=='train':\n",
    "            self.targets = targets\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return torch.FloatTensor(self.data[idx]), torch.FloatTensor(self.targets[idx])\n",
    "        elif self.mode == 'test':\n",
    "            return torch.FloatTensor(self.data[idx]), 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T16:30:02.755896Z",
     "iopub.status.busy": "2020-10-22T16:30:02.754888Z",
     "iopub.status.idle": "2020-10-22T16:37:28.495451Z",
     "shell.execute_reply": "2020-10-22T16:37:28.496258Z"
    },
    "papermill": {
     "duration": 445.769273,
     "end_time": "2020-10-22T16:37:28.496500",
     "exception": false,
     "start_time": "2020-10-22T16:30:02.727227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(cur_model, model_num, train_X_loc, train_Y_loc):\n",
    "    set_seed(seed)\n",
    "    train_set = Dataset_my(train_X_loc, train_Y_loc)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    }\n",
    "\n",
    "    model = cur_model(train_X_loc.shape[1]).to(device)\n",
    "    Path(f'./saved_params/model{model_num}').mkdir(parents=True, exist_ok=True)\n",
    "    checkpoint_path = f'./saved_params/model{model_num}/repeat_{1}_Fold_{1}.pt'\n",
    "    optimizer = optim.Adam(model.parameters(), weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n",
    "    best_loss = {'train': np.inf}\n",
    "\n",
    "    for epoch in range(nepochs):\n",
    "        epoch_loss = {'train': 0.0}\n",
    "\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "\n",
    "            for i, (x, y) in enumerate(dataloaders[phase]):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    preds = model(x)\n",
    "                    loss = criterion(preds, y)\n",
    "\n",
    "                    if phase=='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "        scheduler.step(epoch_loss['train'])\n",
    "        print(\"Epoch {}: {}\".format(epoch, loss.item()))\n",
    "\n",
    "        if epoch_loss['train'] < best_loss['train']:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T16:30:02.755896Z",
     "iopub.status.busy": "2020-10-22T16:30:02.754888Z",
     "iopub.status.idle": "2020-10-22T16:37:28.495451Z",
     "shell.execute_reply": "2020-10-22T16:37:28.496258Z"
    },
    "papermill": {
     "duration": 445.769273,
     "end_time": "2020-10-22T16:37:28.496500",
     "exception": false,
     "start_time": "2020-10-22T16:30:02.727227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_model(cur_model, model_num, test_X_loc):\n",
    "    set_seed(seed)\n",
    "    train_set = Dataset_my(test_X_loc, None, mode='test')\n",
    "\n",
    "    dataloaders = {\n",
    "        'test': DataLoader(train_set, batch_size=val_batch_size, shuffle=False)\n",
    "    }\n",
    "\n",
    "    model = cur_model(test_X_loc.shape[1]).to(device)\n",
    "    checkpoint_path = f'./saved_params/model{model_num}/repeat_{1}_Fold_{1}.pt'\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    model.eval()\n",
    "    \n",
    "    fold_preds = []\n",
    "\n",
    "    for i, (x, y) in enumerate(dataloaders['test']):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_preds = model(x)\n",
    "            fold_preds.append(batch_preds)\n",
    "\n",
    "    fold_preds = torch.cat(fold_preds, dim=0).cpu().numpy()\n",
    "    print(fold_preds.shape)\n",
    "    return fold_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T16:30:02.686535Z",
     "iopub.status.busy": "2020-10-22T16:30:02.684652Z",
     "iopub.status.idle": "2020-10-22T16:30:02.687231Z",
     "shell.execute_reply": "2020-10-22T16:30:02.687689Z"
    },
    "papermill": {
     "duration": 0.025318,
     "end_time": "2020-10-22T16:30:02.687824",
     "exception": false,
     "start_time": "2020-10-22T16:30:02.662506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model4(nn.Module):\n",
    "    def __init__(self, num_columns):\n",
    "        super(Model4, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1024))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1024)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1024, 206))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = F.sigmoid(self.dense3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-22T16:30:01.961409Z",
     "iopub.status.busy": "2020-10-22T16:30:01.960089Z",
     "iopub.status.idle": "2020-10-22T16:30:02.200795Z",
     "shell.execute_reply": "2020-10-22T16:30:02.199707Z"
    },
    "papermill": {
     "duration": 0.257815,
     "end_time": "2020-10-22T16:30:02.200918",
     "exception": false,
     "start_time": "2020-10-22T16:30:01.943103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = test_Y[test_X['real_drug'] == False]\n",
    "for f in t:\n",
    "    t[f] = 0\n",
    "train_Y4 = train_Y.reset_index(drop=True).append(t)\n",
    "train_X4 = train_X.reset_index(drop=True)\n",
    "test_X4 = test_X\n",
    "\n",
    "all_X4 = train_X4.append(test_X4).drop(columns=['real_drug'])\n",
    "\n",
    "features_g = [col for col in train_X4.columns if 'g-' in col]\n",
    "features_c = [col for col in train_X4.columns if 'c-' in col]\n",
    "\n",
    "all_X4['g_sum'] = all_X4[features_g].sum(axis = 1)\n",
    "all_X4['g_mean'] = all_X4[features_g].mean(axis = 1)\n",
    "all_X4['g_std'] = all_X4[features_g].std(axis = 1)\n",
    "all_X4['g_kurt'] = all_X4[features_g].kurtosis(axis = 1)\n",
    "all_X4['g_skew'] = all_X4[features_g].skew(axis = 1)\n",
    "all_X4['c_sum'] = all_X4[features_c].sum(axis = 1)\n",
    "all_X4['c_mean'] = all_X4[features_c].mean(axis = 1)\n",
    "all_X4['c_std'] = all_X4[features_c].std(axis = 1)\n",
    "all_X4['c_kurt'] = all_X4[features_c].kurtosis(axis = 1)\n",
    "all_X4['c_skew'] = all_X4[features_c].skew(axis = 1)\n",
    "all_X4['gc_sum'] = all_X4[features_g + features_c].sum(axis = 1)\n",
    "all_X4['gc_mean'] = all_X4[features_g + features_c].mean(axis = 1)\n",
    "all_X4['gc_std'] = all_X4[features_g + features_c].std(axis = 1)\n",
    "all_X4['gc_kurt'] = all_X4[features_g + features_c].kurtosis(axis = 1)\n",
    "all_X4['gc_skew'] = all_X4[features_g + features_c].skew(axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GaussRankScaler()\n",
    "all_X4 = scaler.fit_transform(all_X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_transformer = PCA(687)\n",
    "all_X4 = pca_transformer.fit_transform(all_X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X4 = all_X4[:train_X4.shape[0]]\n",
    "test_X4 = all_X4[train_X4.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X4 = np.vstack([train_X4, test_X4[test_X['real_drug'] == False]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_smoothing = 0.001\n",
    "train_Y4 = (1 - alpha_smoothing) * train_Y4 + alpha_smoothing * train_Y4.mean(axis=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y4 = train_Y4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.04890693724155426\n",
      "Epoch 1: 0.020866094157099724\n",
      "Epoch 2: 0.021317237988114357\n",
      "Epoch 3: 0.018429653719067574\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 4: 0.016221515834331512\n",
      "Epoch 5: 0.01831035129725933\n",
      "Epoch 6: 0.015584965236485004\n",
      "Epoch 7: 0.01988513581454754\n",
      "Epoch 8: 0.01612839102745056\n",
      "Epoch 9: 0.017518268898129463\n",
      "Epoch 10: 0.01633915677666664\n",
      "Epoch 11: 0.018052853643894196\n",
      "Epoch 12: 0.018274301663041115\n",
      "Epoch 13: 0.015799714252352715\n",
      "Epoch 14: 0.016889508813619614\n",
      "Epoch 15: 0.015291029587388039\n",
      "Epoch 16: 0.015147121623158455\n",
      "Epoch 17: 0.013446547091007233\n",
      "Epoch 18: 0.015235004015266895\n",
      "Epoch 19: 0.01599959284067154\n",
      "Epoch 20: 0.014237137511372566\n",
      "Epoch 21: 0.016841525211930275\n",
      "Epoch 22: 0.01475224457681179\n",
      "Epoch 23: 0.012747309170663357\n",
      "Epoch 24: 0.013497750274837017\n",
      "Epoch 25: 0.015094495378434658\n",
      "Epoch 26: 0.015711262822151184\n",
      "Epoch 27: 0.013944294303655624\n",
      "Epoch 28: 0.013858674094080925\n",
      "Epoch 29: 0.013367187231779099\n",
      "Epoch 30: 0.014111164957284927\n",
      "Epoch 31: 0.011623430997133255\n",
      "Epoch 32: 0.012401072308421135\n",
      "Epoch 33: 0.013461350463330746\n",
      "Epoch 34: 0.012167755514383316\n",
      "Epoch 35: 0.011700262315571308\n",
      "Epoch 36: 0.013204598799347878\n",
      "Epoch 37: 0.012676144018769264\n",
      "Epoch 38: 0.011395208537578583\n",
      "Epoch 39: 0.011711965315043926\n",
      "Epoch 40: 0.012592289596796036\n",
      "Epoch 41: 0.010923771187663078\n",
      "Epoch 42: 0.011925204657018185\n",
      "Epoch 43: 0.012227749451994896\n",
      "Epoch 44: 0.010041963309049606\n",
      "Epoch 45: 0.008367134258151054\n",
      "Epoch 46: 0.009449872188270092\n",
      "Epoch 47: 0.01051353570073843\n",
      "Epoch 48: 0.010732779279351234\n",
      "Epoch 49: 0.011715797707438469\n"
     ]
    }
   ],
   "source": [
    "train_model(Model4, 4, train_X4, train_Y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24172, 206)\n"
     ]
    }
   ],
   "source": [
    "train_P4 = predict_model(Model4, 4, train_X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_P4[:train_X.shape[0]][train_X['real_drug'] == False] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_P4[train_X.shape[0]:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04231147858123351"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(train_Y4, train_P4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "papermill": {
   "duration": 469.854705,
   "end_time": "2020-10-22T16:37:38.321100",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-22T16:29:48.466395",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
